{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necessary libraries for data analysis, preprocessing, modeling, and visualization.\n",
    "\n",
    "Creates an output directory named 'output' if it doesn't exist. This will be used to store output files or visualizations generated later in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from functions import utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 0.75em;\">\n",
    "\n",
    "# Financial Literacy Data Processing\n",
    "\n",
    "This script processes and cleans datasets from two different years (2017 and 2020) related to financial literacy. The final output is a prepared DataFrame ready for further analysis or modeling. Below is a step-by-step explanation of the process:\n",
    "\n",
    "## 1. Load Datasets and Compare Columns\n",
    "The script begins by loading two datasets, one from 2017 and the other from 2020. It then compares the columns of these datasets:\n",
    "- If the columns match, a message `\"PASS_20_17\"` is printed.\n",
    "- If the columns do not match, the differences are identified and displayed.\n",
    "\n",
    "## 2. Merge DataFrames and Initial Cleaning\n",
    "Next, the two datasets are merged into a single DataFrame. Some initial data cleaning is performed:\n",
    "- A new column `key` is added as a unique identifier, which is then set as the index of the DataFrame.\n",
    "- The redundant `id` column is dropped.\n",
    "\n",
    "## 3. Preprocess `qprod1_d`, `qprod2`, `qk4`, `qk5`, and `qf10_*` Variables\n",
    "Certain variables require specific preprocessing:\n",
    "- Missing values in specific columns (`qprod1_d` and `qprod2`) are filled with predefined values (`99` and `-99`, respectively).\n",
    "- The variables `qk4` and `qk5` are recoded, grouping the answers of variables qk4 and qk5, imposing 1 on all incorrect answers.\n",
    "- Variables that start with `qf10_` have invalid values (`-97`, `-99`) replaced with the mode (most frequent value) of each column to get an integer variable.\n",
    "\n",
    "## 4. Define and Encode Variables\n",
    "The script then categorizes the variables into three types:\n",
    "- **Binary variables**: Variables with binary (0/1) responses.\n",
    "- **Integer variables**: Variables with integer responses, including the `qf10_*` variables.\n",
    "- **Continuous variables**: Variables with continuous numeric responses (e.g., `pesofitc`).\n",
    "\n",
    "The remaining columns are treated as **categorical variables**. These categorical variables are encoded using `OneHotEncoder`, which converts them into binary (0/1) features.\n",
    "\n",
    "## 5. Create and Finalize the Final DataFrame\n",
    "The final DataFrame (`db_final`) is created by combining the binary, integer, and encoded categorical variables. Any remaining missing values are filled with `0`.\n",
    "\n",
    "## 6. Check for Missing Values\n",
    "Lastly, the script checks if there are any remaining missing values in the final DataFrame:\n",
    "- If missing values are detected, a warning message is printed.\n",
    "- If there are no missing values, a success message is displayed.\n",
    "\n",
    "This structured approach ensures that the data is clean, consistent, and ready for any further analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS_20_17\n",
      "No missing values.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Datasets and Compare Columns\n",
    "df_2017 = pd.read_csv(\"data/Dataset - Financial literacy/Financia_literacy_2017.csv\")\n",
    "df_2020 = pd.read_csv(\"data/Dataset - Financial literacy/Financia_literacy_2020.csv\")\n",
    "\n",
    "if (df_2020.columns == df_2017.columns).all():\n",
    "    print(\"PASS_20_17\")\n",
    "else:\n",
    "    print(\"FAIL_20_17\")\n",
    "    print(\"df_20: YES , df_17: NO\", set(df_2020.columns) - set(df_2017.columns))\n",
    "    print(\"df_17: YES , df_20: NO\", set(df_2017.columns) - set(df_2020.columns))\n",
    "\n",
    "# 2. Merge DataFrames and creates a new index\n",
    "db = pd.concat([df_2017, df_2020], axis=0, ignore_index=True)\n",
    "db['key'] = range(len(db))\n",
    "db.set_index('key', inplace=True)\n",
    "db.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "# 3. Preprocess qprod1_d, qprod2, qk4, qk5, and qf10_* Variables\n",
    "db.fillna({\"qprod1_d\": 99, \"qprod2\": -99}, inplace=True)\n",
    "\n",
    "db['qk4'] = np.where(db['qk4'].isin([-97, -99, 0]), db['qk4'], 1)\n",
    "db['qk5'] = np.where(db['qk5'].isin([-97, -99, 102]), db['qk5'], 1)\n",
    "\n",
    "qf10_cols = [col for col in db.columns if col.startswith(\"qf10_\")]\n",
    "for col in qf10_cols:\n",
    "    mode_value = db[col].mode()[0]\n",
    "    db[col] = db[col].replace([-97, -99], mode_value)\n",
    "\n",
    "# 4. Define Variables Type and Encode Variables Categorical ones\n",
    "binary_variables = [\n",
    "    \"qd1\", \"SM\", \"qd12\", \"qprod1c_1\", \"qprod1c_2\", \"qprod1c_3\", \"qprod1c_5\", \"qprod1c_6\", \"qprod1c_7\",\n",
    "    \"qprod1c_8\", \"qprod1c_10\", \"qprod1c_11\", \"qprod1c_12\", \"qprod1c_14\", \"qprod1c_99\", \"qf3_1\", \"qf3_3\", \"qf3_4\",\n",
    "    \"qf3_6\", \"qf3_7\", \"qf3_8\", \"qf3_99\", \"qf9_1\", \"qf9_10\", \"qf9_2\", \"qf9_3\", \"qf9_4\", \"qf9_5\", \"qf9_6\", \"qf9_7\",\n",
    "    \"qf9_8\", \"qf9_9\", \"qf9_99\", \"qprod3_1\", \"qprod3_2\", \"qprod3_3\", \"qprod3_4\", \"qprod3_5\", \"qprod3_6\", \"qprod3_7\",\n",
    "    \"qprod3_8\", \"qprod3_9\", \"qprod3_10\", \"qprod3_11\", \"qprod3_12\", \"qprod3_13\", \"qprod3_14\", \"qprod3_15\", \"qprod3_16\",\n",
    "    \"qprod3_17\", \"qprod3_18\", \"qprod3_99\", \"qf12_1_a\", \"qf12_1_b\", \"qf12_1_c\", \"qf12_2_d\", \"qf12_3_e\", \"qf12_3_f\",\n",
    "    \"qf12_3_g\", \"qf12_4_k\", \"qf12_4_l\", \"qf12_5_m\", \"qf12_5_o\", \"qf12_6_p\", \"qf12_6_q\", \"qf12_7_r\", \"qf12_97\", \"qf12_99\"\n",
    "]\n",
    "integer_variables = [\"qd5b\", \"qd7\"] + qf10_cols\n",
    "continuous_variables = [\"pesofitc\"]\n",
    "\n",
    "categorical_variables = db.columns.difference(binary_variables + integer_variables + continuous_variables)\n",
    "\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "encoded_cols = encoder.fit_transform(db[categorical_variables])\n",
    "encoded_df = pd.DataFrame(encoded_cols.toarray(), columns=encoder.get_feature_names_out(categorical_variables))\n",
    "\n",
    "# 5. Create and Finalize the Final DataFrame\n",
    "db_final = pd.concat([db[binary_variables + integer_variables], encoded_df], axis=1).fillna(0)\n",
    "\n",
    "# 6. Check for Missing Values\n",
    "if db_final.isna().any().any():\n",
    "    print(\"Missing values exist.\")\n",
    "else:\n",
    "    print(\"No missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 1em;\">\n",
    "\n",
    "### Variable Selection for Financial Literacy Analysis\n",
    "\n",
    "In this analysis, I have specifically defined and selected variables based on the questions from the questionnaire that are directly used to calculate the financial literacy scores.\n",
    "\\\\\n",
    "These variables are categorized into three key components: **knowledge**, **behavior**, and **attitude**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_score = [\"qk3_2\",\"qk3_3\",\"qk3_-97\",\"qk3_1\", #qk3\n",
    "                       \"qk4_1\",\"qk4_-97\",\"qk4_0\", #qk4\n",
    "                       \"qk5_1\",\"qk5_-97\",\"qk5_102\", #qk5\n",
    "                       \"qk6_2\",\"qk6_3\",\"qk6_4\",\"qk6_-97\",\"qk6_1\", #qk6\n",
    "                       \"qk7_1_0\",\"qk7_1_-97\",\"qk7_1_1\", #qk7_1\n",
    "                       \"qk7_2_0\",\"qk7_2_-97\",\"qk7_2_1\", #qk7_2\n",
    "                       \"qk7_3_0\",\"qk7_3_-97\",\"qk7_3_1\",] #qk7_3\n",
    "\n",
    "behevioral_score =  [\"qf1_2\",\"qf1_3\",\"qf1_1\", #qf1\n",
    "                        \"qf2_0\",\"qf2_1\", #qf2\n",
    "                        \"qf3_1\",\"qf3_3\",\"qf3_4\",\"qf3_6\",\"qf3_7\",\"qf3_8\",\"qf3_99\", #qf3\n",
    "                        \"qf10_1\", #qf10_1\n",
    "                        \"qf10_4\", #qf10_4\n",
    "                        \"qf10_6\", #qf10_6\n",
    "                        \"qf10_7\", #qf10_7\n",
    "                        \"qprod2_2.0\",\"qprod2_3.0\",\"qprod2_4.0\",\"qprod2_1.0\", #qprod2\n",
    "                        \"qprod3_1\",\"qprod3_2\",\"qprod3_3\",\"qprod3_4\",\"qprod3_5\",\"qprod3_6\",\"qprod3_7\",\"qprod3_8\",\"qprod3_9\",\"qprod3_10\",\"qprod3_11\",\"qprod3_12\",\"qprod3_13\",\"qprod3_14\",\"qprod3_15\",\"qprod3_16\",\"qprod3_17\",\"qprod3_18\",\"qprod3_99\", #qprod3\n",
    "                        \"qf12_1_a\",\"qf12_1_b\",\"qf12_1_c\",\"qf12_2_d\",\"qf12_3_e\",\"qf12_3_f\",\"qf12_3_g\",\"qf12_4_k\",\"qf12_4_l\",\"qf12_5_m\",\"qf12_5_o\",\"qf12_6_p\",\"qf12_6_q\",\"qf12_7_r\",\"qf12_97\",\"qf12_99\" #qf12\n",
    "                        ]\n",
    "\n",
    "attitude_score = [\"qf10_2\",\"qf10_3\",\"qf10_8\"] #qf10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
