{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pipeline import data_preparation\n",
    "from helpers import utils_analysis\n",
    "from helpers import utils_data_preparation\n",
    "import os \n",
    "from config import *\n",
    "\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 00:07:05,468 - INFO - Starting financial literacy data processing...\n",
      "2025-04-29 00:07:05,470 - INFO - Loading data from data/Financia_literacy_2017.csv...\n",
      "2025-04-29 00:07:05,519 - INFO - Data loaded successfully.\n",
      "2025-04-29 00:07:05,522 - INFO - Applying data transformation steps...\n",
      "2025-04-29 00:07:05,524 - INFO - Handling missing values...\n",
      "2025-04-29 00:07:05,531 - INFO - Modifying specific columns...\n",
      "2025-04-29 00:07:05,539 - INFO - Replacing -97 and -99 with mode for columns: ['qf10_1', 'qf10_2', 'qf10_3', 'qf10_4', 'qf10_5', 'qf10_6', 'qf10_7', 'qf10_8', 'qf10_9', 'qf10_10', 'qf10_11', 'qf10_12']\n",
      "2025-04-29 00:07:05,615 - INFO - Applying one-hot encoding to categorical variables...\n",
      "2025-04-29 00:07:05,760 - INFO - Categorizing education and generation...\n",
      "2025-04-29 00:07:05,773 - INFO - No missing values found in the DataFrame.\n",
      "2025-04-29 00:07:05,775 - INFO - Data transformation completed.\n"
     ]
    }
   ],
   "source": [
    "data = data_preparation.process_financial_literacy_data(\"data/Financia_literacy_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 00:07:05,797 - INFO - Creating 'segmentation' variable...\n",
      "2025-04-29 00:07:05,799 - INFO - Creating combined variable 'segmentation' from 'education' and 'generation'...\n",
      "2025-04-29 00:07:05,803 - INFO - Combined variable 'segmentation' created successfully.\n",
      "2025-04-29 00:07:05,805 - INFO - Variable 'segmentation' created successfully.\n",
      "2025-04-29 00:07:05,807 - INFO - Calculating scores...\n",
      "2025-04-29 00:07:05,809 - INFO - Calculating all scores...\n",
      "2025-04-29 00:07:05,853 - INFO - All scores calculated successfully.\n",
      "2025-04-29 00:07:05,854 - INFO - Score calculation completed.\n",
      "2025-04-29 00:07:05,855 - INFO - Creating analysis DataFrame...\n",
      "2025-04-29 00:07:05,856 - INFO - Creating db_analysis DataFrame...\n",
      "2025-04-29 00:07:05,871 - INFO - db_analysis DataFrame created successfully.\n",
      "2025-04-29 00:07:05,872 - INFO - Analysis DataFrame created successfully.\n",
      "2025-04-29 00:07:05,877 - INFO - Segmentation counts: {'Diploma_Millennials': 337, 'No_diploma_Boomers': 309, 'Diploma_Gen_X': 262, 'No_diploma_Gen_X': 232, 'University_Millennials': 199, 'No_diploma_Millennials': 191, 'Diploma_Gen_Z': 172, 'University_Gen_Z': 164, 'Diploma_Boomers': 139, 'No_diploma_Gen_Z': 105, 'University_Gen_X': 98, 'No_diploma_Silent_Generation': 77, 'University_Boomers': 69, 'Diploma_Silent_Generation': 15, 'University_Silent_Generation': 7}\n",
      "2025-04-29 00:07:05,879 - INFO - Segmentation values with minimum weight (200): ['Diploma_Millennials', 'No_diploma_Boomers', 'Diploma_Gen_X', 'No_diploma_Gen_X']\n",
      "2025-04-29 00:07:05,880 - INFO - Adding a random variable for 10-fold cross-validation...\n",
      "2025-04-29 00:07:05,885 - INFO - Random variable for cross-validation added successfully.\n",
      "2025-04-29 00:07:05,886 - INFO - Analysis DataFrame preparation completed.\n"
     ]
    }
   ],
   "source": [
    "prepared_data = data_preparation.analysis_dataframe_preparation(data, \"education\", \"generation\",  min_weight, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 00:08:26,117 - INFO - Starting cross-validation for association rules analysis.\n",
      "2025-04-29 00:08:26,122 - INFO - Processing segment: Diploma_Millennials\n",
      "2025-04-29 00:08:26,124 - INFO - Processing fold 1/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:10:15,205 - INFO - Processing fold 2/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:12:01,023 - INFO - Processing fold 3/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:13:44,538 - INFO - Processing fold 4/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:15:24,823 - INFO - Processing fold 5/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:17:05,645 - INFO - Processing fold 6/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:18:45,295 - INFO - Processing fold 7/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:20:24,163 - INFO - Processing fold 8/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:22:02,910 - INFO - Processing fold 9/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:23:42,729 - INFO - Processing fold 10/10 for segment Diploma_Millennials...\n",
      "2025-04-29 00:24:54,772 - INFO - Processing segment: No_diploma_Boomers\n",
      "2025-04-29 00:24:54,773 - INFO - Processing fold 1/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:26:01,149 - INFO - Processing fold 2/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:27:07,323 - INFO - Processing fold 3/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:28:14,791 - INFO - Processing fold 4/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:29:17,660 - INFO - Processing fold 5/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:30:25,076 - INFO - Processing fold 6/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:31:18,155 - INFO - Processing fold 7/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:32:24,609 - INFO - Processing fold 8/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:33:30,559 - INFO - Processing fold 9/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:34:38,139 - INFO - Processing fold 10/10 for segment No_diploma_Boomers...\n",
      "2025-04-29 00:35:44,411 - INFO - Processing segment: Diploma_Gen_X\n",
      "2025-04-29 00:35:44,412 - INFO - Processing fold 1/10 for segment Diploma_Gen_X...\n",
      "2025-04-29 00:37:12,710 - INFO - Processing fold 2/10 for segment Diploma_Gen_X...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_results, summary \u001b[38;5;241m=\u001b[39m \u001b[43mutils_analysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_association_rules_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegmentation_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegmentation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegmentation_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns_A\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknowledge_score_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns_B\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbehavioral_score_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massociation_rules_cv_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lore9\\Documents\\GitHub\\Data_Science_Lab\\helpers\\utils_analysis.py:455\u001b[0m, in \u001b[0;36manalyze_association_rules_cv\u001b[1;34m(df, segmentation_column, segmentation_values, columns_A, columns_B, export_name, min_support, min_confidence, min_lift, n_folds)\u001b[0m\n\u001b[0;32m    452\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSegment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no data. Skipping.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m fold_results_df \u001b[38;5;241m=\u001b[39m \u001b[43m_process_segment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegment_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_confidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_folds\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fold_results_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    460\u001b[0m     aggregated_results \u001b[38;5;241m=\u001b[39m fold_results_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\lore9\\Documents\\GitHub\\Data_Science_Lab\\helpers\\utils_analysis.py:301\u001b[0m, in \u001b[0;36m_process_segment\u001b[1;34m(segment_data, segment, columns_A, columns_B, min_support, min_confidence, min_lift, n_folds)\u001b[0m\n\u001b[0;32m    298\u001b[0m ar \u001b[38;5;241m=\u001b[39m AssociationRules(train_data, columns_A\u001b[38;5;241m=\u001b[39mcolumns_A, columns_B\u001b[38;5;241m=\u001b[39mcolumns_B, group\u001b[38;5;241m=\u001b[39msegment)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# Calculate metrics for training data\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m train_results \u001b[38;5;241m=\u001b[39m \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_all_metrics_for_selected_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_results\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    304\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo rules generated for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in segment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lore9\\Documents\\GitHub\\Data_Science_Lab\\helpers\\utils_analysis.py:155\u001b[0m, in \u001b[0;36mAssociationRules.calculate_all_metrics_for_selected_sets\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m combinations_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_duplicate_combinations(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_combinations(valid_columns_B), valid_columns_B)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Calculate metrics in parallel\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_metrics_for_pair\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitemset_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitemset_B\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitemset_A\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcombinations_A\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitemset_B\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcombinations_B\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitemset_A\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdisjoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitemset_B\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure A and B are disjoint\u001b[39;49;00m\n\u001b[0;32m    160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "File \u001b[1;32mc:\\Users\\lore9\\Documents\\GitHub\\Data_Science_Lab\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lore9\\Documents\\GitHub\\Data_Science_Lab\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lore9\\Documents\\GitHub\\Data_Science_Lab\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_results, summary = utils_analysis.analyze_association_rules_cv(\n",
    "    df=prepared_data[1],\n",
    "    segmentation_column=\"segmentation\",\n",
    "    segmentation_values=prepared_data[2],\n",
    "    columns_A=knowledge_score_variables,\n",
    "    columns_B=behavioral_score_variables,\n",
    "    export_name=\"association_rules_cv_results\",\n",
    "    n_folds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_analysis.plot_metrics_distribution(final_results_knowledge_behavioral, save_path=\"output\\\\output_plots\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
